{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#auto reload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alhus\\.conda\\envs\\projetmla\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_dataloader), (val_data, val_dataloader), (bow_en, bow_fr) = load_data(10000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  258, 30000,    26,  ..., 30000,     0,  1027],\n",
      "        [30000,   223, 30000,  ..., 30000, 30000, 30000],\n",
      "        [   86,   183,    27,  ...,  3287,   859,    27],\n",
      "        ...,\n",
      "        [   62,    39,  1302,  ..., 30000, 30000, 30000],\n",
      "        [    5,  1095, 30000,  ..., 30000, 30000, 30000],\n",
      "        [   11,     7,  5914,  ..., 30000, 30000, 30000]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataloader:\n",
    "    print(x[\"english\"][\"idx\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-EXISTANT NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8668778997501817\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "hypothesis=['Le','chat','se','trouve','sur','le','toit']\n",
    "reference=['Le','chat','se','trouve','sur','le','toit','bla']\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis) \n",
    "print(BLEUscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-SCORE PERSONNALISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.392814650900513\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "def ngram_precision(candidate, reference, n):\n",
    "    candidate_ngrams = [tuple(candidate[i:i+n]) for i in range(len(candidate)-n+1)]\n",
    "    reference_ngrams = [tuple(reference[i:i+n]) for i in range(len(reference)-n+1)]\n",
    "\n",
    "    candidate_ngram_counts = collections.Counter(candidate_ngrams)\n",
    "    reference_ngram_counts = collections.Counter(reference_ngrams)\n",
    "\n",
    "    overlap_count = sum((candidate_ngram_counts & reference_ngram_counts).values())\n",
    "    total_count = max(1, len(candidate_ngrams))\n",
    "\n",
    "    precision = overlap_count / total_count\n",
    "    return precision\n",
    "\n",
    "def bleu_score(candidate, references, weights):\n",
    "    precisions = []\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        n = i + 1\n",
    "        precision = ngram_precision(candidate, references, n)\n",
    "        precisions.append(precision)\n",
    "\n",
    "    geometric_mean = math.exp(sum(weights[i] * math.log(p) for i, p in enumerate(precisions)))\n",
    "\n",
    "    brevity_penalty = min(1, len(candidate) / max(len(reference) for reference in references))\n",
    "\n",
    "    bleu = brevity_penalty * geometric_mean\n",
    "    return bleu\n",
    "\n",
    "# Exemple d'utilisation\n",
    "reference = ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "candidate = ['the', 'fast', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "\n",
    "candidate=['Le','chat','se','trou','s','le','to','bli']\n",
    "reference=['Le','chat','se','trouve','sur','le','toit']\n",
    "\n",
    "weights = [0.25,0.25,0.25] # You can adjust the weights based on your preference\n",
    "\n",
    "score = bleu_score(candidate, reference, weights)\n",
    "print(\"BLEU Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "#matmul tests: \n",
    "batch_size = 2 \n",
    "Tx = 3 \n",
    "hidden_size = 4\n",
    "a = torch.randint(0,10,(batch_size, Tx),dtype=torch.float)\n",
    "h = torch.randint(0,10,(batch_size, Tx, hidden_size),dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 4., 7.],\n",
       "        [0., 1., 6.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 3.],\n",
       "         [7., 1., 2.],\n",
       "         [9., 5., 0.],\n",
       "         [5., 6., 9.]],\n",
       "\n",
       "        [[8., 0., 7.],\n",
       "         [0., 0., 7.],\n",
       "         [9., 1., 0.],\n",
       "         [2., 3., 1.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape,a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21.,  81., 101., 132.],\n",
       "        [ 42.,  42.,   1.,   9.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h.swapaxes(1,2) @ a.unsqueeze(2)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlaproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
