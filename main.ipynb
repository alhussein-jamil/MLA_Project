{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#auto reload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  prep_data import load_data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alhus\\.conda\\envs\\projetmla\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_dataloader), (val_data, val_dataloader), (bow_en, bow_fr) = load_data(10000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   30,    25,     3,  ..., 30000, 30000, 30000],\n",
      "        [  223, 30000, 30000,  ...,    10,     0, 30000],\n",
      "        [  465, 30000,    11,  ...,    89,   808,     1],\n",
      "        ...,\n",
      "        [  126,     1,     0,  ..., 30000, 30000, 30000],\n",
      "        [ 1676, 30000,    13,  ..., 30000, 30000, 30000],\n",
      "        [   13,    85,    73,  ..., 30000, 30000, 30000]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataloader:\n",
    "    print(x[\"english\"][\"idx\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_word(idx: torch.Tensor, vocab: List):\n",
    "    return \" \".join(list(vocab[idx[(idx < len(vocab))]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of and to a in for is on that by'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_word(torch.tensor([1,2,3,4,5,6,7,8,9,10,30000,30000,30000,30000,30000,30000,30000,30000]), data['bow']['english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector(ids, vocab_size):\n",
    "    vecs = torch.zeros(len(ids), vocab_size)\n",
    "    vecs[range(len(ids)), ids] = 1\n",
    "    return vecs\n",
    "\n",
    "class to_vec:\n",
    "    def __init__(self, tor, vocab_size, lang):\n",
    "        self.tor = tor\n",
    "        self.vocab_size = vocab_size\n",
    "        self.lang = lang\n",
    "\n",
    "    \n",
    "    def __call__(self, ids):\n",
    "        ids = self.tor.tensor(ids[\"ids_{}\".format(self.lang)])\n",
    "        vecs = self.tor.zeros(len(ids), self.vocab_size)\n",
    "        vecs[range(len(ids)), ids] = 1\n",
    "        return vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-EXISTANT NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8668778997501817\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "hypothesis=['Le','chat','se','trouve','sur','le','toit']\n",
    "reference=['Le','chat','se','trouve','sur','le','toit','bla']\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis) \n",
    "print(BLEUscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-SCORE PERSONNALISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.392814650900513\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "\n",
    "def ngram_precision(candidate, reference, n):\n",
    "    candidate_ngrams = [tuple(candidate[i:i+n]) for i in range(len(candidate)-n+1)]\n",
    "    reference_ngrams = [tuple(reference[i:i+n]) for i in range(len(reference)-n+1)]\n",
    "\n",
    "    candidate_ngram_counts = collections.Counter(candidate_ngrams)\n",
    "    reference_ngram_counts = collections.Counter(reference_ngrams)\n",
    "\n",
    "    overlap_count = sum((candidate_ngram_counts & reference_ngram_counts).values())\n",
    "    total_count = max(1, len(candidate_ngrams))\n",
    "\n",
    "    precision = overlap_count / total_count\n",
    "    return precision\n",
    "\n",
    "def bleu_score(candidate, references, weights):\n",
    "    precisions = []\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        n = i + 1\n",
    "        precision = ngram_precision(candidate, references, n)\n",
    "        precisions.append(precision)\n",
    "\n",
    "    geometric_mean = math.exp(sum(weights[i] * math.log(p) for i, p in enumerate(precisions)))\n",
    "\n",
    "    brevity_penalty = min(1, len(candidate) / max(len(reference) for reference in references))\n",
    "\n",
    "    bleu = brevity_penalty * geometric_mean\n",
    "    return bleu\n",
    "\n",
    "# Exemple d'utilisation\n",
    "reference = ['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "candidate = ['the', 'fast', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n",
    "\n",
    "candidate=['Le','chat','se','trou','s','le','to','bli']\n",
    "reference=['Le','chat','se','trouve','sur','le','toit']\n",
    "\n",
    "weights = [0.25,0.25,0.25] # You can adjust the weights based on your preference\n",
    "\n",
    "score = bleu_score(candidate, reference, weights)\n",
    "print(\"BLEU Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "#matmul tests: \n",
    "batch_size = 2 \n",
    "Tx = 3 \n",
    "hidden_size = 4\n",
    "a = torch.randint(0,10,(batch_size, Tx),dtype=torch.float)\n",
    "h = torch.randint(0,10,(batch_size, Tx, hidden_size),dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 3., 2.],\n",
       "        [8., 7., 2.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 7., 7.],\n",
       "         [5., 4., 2.],\n",
       "         [5., 5., 2.],\n",
       "         [2., 5., 5.]],\n",
       "\n",
       "        [[9., 8., 8.],\n",
       "         [2., 8., 8.],\n",
       "         [7., 1., 0.],\n",
       "         [6., 9., 4.]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape,a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 59.,  46.,  49.,  37.],\n",
       "        [144.,  88.,  63., 119.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h.swapaxes(1,2) @ a.unsqueeze(2)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlaproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
