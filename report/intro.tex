
\textbf{}
Machine translation is the task of automatically translating text from one language to another. Traditional approaches to machine translation rely on statistical models that learn to map source language sentences to target language sentences based on large parallel corpora. However, these models often suffer from the problem of data sparsity, and require extensive feature engineering to achieve good performance. In recent years, neural machine translation (NMT) has emerged as a promising alternative to traditional statistical machine translation. NMT models use neural networks to learn to translate directly from source to target language, without relying on hand-crafted features or alignment models. In this report, we present our implementation of a neural machine translation model that jointly learns to align and translate, based on the work of Bahdanau et al. (2015). We aim to assess the performance of our model on the English-French translation task with the WMT14 dataset, and contrast its results with those of a baseline model employing a simple encoder-decoder architecture. Our objective is to not only gauge the effectiveness of the proposed approach but also to delve into the model's behavior through a detailed analysis of its alignment patterns. The full implementation is available on github \href{https://github.com/alhussein-jamil/MLA_Project}{Neural Machine Translation by Jointly Learning to Align and Translate paper implementation} 