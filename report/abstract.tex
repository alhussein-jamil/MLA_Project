
\begin{abstract}

% \textbf{As part of our Advanced Machine Learning project, we embarked on the re-implementation of a neural machine translation system outlined in a research paper. This model serves the purpose of translating sentences from a source language to a target language. Its architecture is composed of three key elements: an encoder, responsible for processing and encoding input sentences into variable-length vectors; a decoder, tasked with generating translated sentences in the target language; and an attention mechanism positioned between the encoder and decoder. This attention mechanism plays a crucial role in considering the contextual information of each word in the input sentence, taking into account both preceding and succeeding words for a more comprehensive translation.}
\textbf{Neural machine translation (NMT) is a recent approach to machine translation that has shown promising results in terms of translation quality. In this report, we present our implementation of a neural machine translation model that jointly learns to align and translate, based on the work of Bahdanau et al. (2015). We evaluate our model on the English-French translation task using the WMT14 dataset, and compare its performance to a baseline model that uses a basic encoder-decoder architecture. Our results show that the proposed approach outperforms the baseline model in terms of BLEU score and alignment quality.}
\end{abstract}


